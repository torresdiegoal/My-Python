{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolmogorov-Smirnov Test\n",
    "\n",
    "\n",
    "Kolmogorov - Smirnov (KS) test is a non-parametric test to compare the equality of two continuous one dimensional probability distributions. In this test, we quantify the distance (absolute difference) between distributions. These two distributions could be two different sample, **or one could be sample and another one a theoretical distribution**. Let us test if our generated normal random variable follow normal distribution or not. st.kstest is the function to to perform KS test.\n",
    "\n",
    "![KS Hypothesis](KS_plot.png)\n",
    "\n",
    "The graph shows two curves: the red line is **CDF** or the **Cumulative distribution function** of the theorical distribution, whilst the blue one is the **empirical CDF**, which is the distribution of the sample.\n",
    "\n",
    "The test answers the question \"How likely is it that we would see a collection of samples like this if they were drawn from that probability distribution?\" or, in the second case, \"How likely is it that we would see two sets of samples like this if they were drawn from the same (but unknown) probability distribution?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1768260698073626\n"
     ]
    }
   ],
   "source": [
    "# generamos numeros aleatorios distribuidos normalmente, similar a rnorm() de R\n",
    "x = np.random.randn(1000)\n",
    "\n",
    "# Kolmogorov-Smirnov Test  # D the greatest or max vertical distance between the two distributions\n",
    "                           # x and the theorical 'norm', in other words, the KS statistic\n",
    "D,p = st.kstest(x,'norm') # p -> p-value\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![KS Hypothesis](hypothesis_Kolmogorov_Smirnov.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a p-value higher than the threshold, which means that our generated normally distributed random variable is in fact normal. We can also test if the the generated uniformly distributed random variable are not normal by chance. In this we get a p-value less than the threshold, which means that our generated random numbers in this case are not normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.988092097923799e-232\n"
     ]
    }
   ],
   "source": [
    "# genera numeros aleatorios en el intervalo [0, 1) con una distribuci√≥n uniforme\n",
    "y = np.random.rand(1000) \n",
    "\n",
    "D, p = st.kstest(y,'norm')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496\n",
      "4.361853008614382e-112\n"
     ]
    }
   ],
   "source": [
    "D,p = st.kstest(y,x)\n",
    "print(D)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
