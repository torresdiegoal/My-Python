{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de6972f5-5a6f-41cc-b948-2a031441eaeb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Transformaciones correspondientes a la capa silver de la tabla de contacts\n",
    "Este notebook contiene el código para leer la tabla de contacts y realizar los respectivos cruces.\n",
    "\n",
    "## Objetivos\n",
    "Los objetivos de este notebook son:\n",
    "\n",
    "* Lectura de tabla de la capa bronze azuresql\n",
    "* Transformacion y limpieza del campo CIUDAD\n",
    "* Escribir el resultado\n",
    "\n",
    "## Creacion \n",
    "* Autor: Diego Torres\n",
    "* Fecha creación: 27/11/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ec47b3-8f65-4d87-bc96-d4ca42c64cbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting unidecode\n",
      "  Using cached Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.8\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "%pip install unidecode\n",
    "#%pip install re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018d6cdd-227d-45af-b206-f61235318816",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d44eba3-9be5-40b2-82f9-7341598d9111",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, lower,col,when,to_timestamp,to_date,coalesce,lit,year,month,split\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "# Crear una SparkSession\n",
    "spark = SparkSession.builder.appName(\"AzureSQL\").getOrCreate()\n",
    "\n",
    "## Credenciales BD\n",
    "inpath = \"C:/Users/diego.torres/OneDrive/Datasets/Tuboleta/Credenciales.txt\"\n",
    "keys = pd.read_csv(inpath, sep = ',')\n",
    "display(keys)\n",
    "\n",
    "# Creo variables para cada fila del DataFrame que contiene las credenciales de la bd\n",
    "for index, row in keys.iterrows():\n",
    "    variable_name = row['key']\n",
    "    variable_value = row['value']\n",
    "    globals()[variable_name] = variable_value\n",
    "\n",
    "# Configurar las propiedades de la conexión\n",
    "jdbc_url = f\"jdbc:sqlserver://{jdbc_hostname}:1433;database={jdbc_database_datamart}\"\n",
    "jdbc_properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": driver\n",
    "}\n",
    "\n",
    "# Conexion al Blob\n",
    "spark.conf.set(clave_blob, access_key_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e3798f0-43d2-4a4d-90b4-b7ea78980335",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "###  Importe de Contacts  ###\n",
    "inpath = \"abfss://storagebi@tbdwhstorage01.dfs.core.windows.net/bronze/contacts/Ds_B_Contacts_parquet/\"\n",
    "df_ini = spark.read.parquet(inpath)\n",
    "\n",
    "#df_ini.count()\n",
    "#display(df_ini.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78b17fac-71df-4866-844c-7461d092107f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#temp = df_ini.filter(col('T_CONTACT_ID') == '10229527487512')#LAST_MODIFICATION\n",
    "# temp = df_ini.select('LAST_MODIFICATION','LAST_UPDATE').distinct()\n",
    "# display(temp.limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d498c9d0-e1dd-407b-bef6-93fa1f4bdb0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #temp = df_ini.filter(col('T_CONTACT_ID') == '10229527487512')#LAST_MODIFICATION\n",
    "# temp = df_ini.select(lower('MAIN_ADDR_LINE1'))\n",
    "# print(temp.count())\n",
    "# temp = df_ini.select(lower('MAIN_ADDR_LINE1')).distinct()\n",
    "# print(temp.count())\n",
    "# display(temp.limit(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2e0ed4-f6ef-438c-ab3d-58999f39a6b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Dividir cada línea en palabras y extraer la primera palabra\n",
    "# df_with_first_word = df_ini.withColumn(\"primera_palabra\", split(df_ini[\"MAIN_ADDR_LINE1\"], \" \")[0])\n",
    "\n",
    "# # Comprobar si la primera palabra contiene \"calle\", \"carrera\" u otras variantes\n",
    "# # df_with_extraction = df_with_first_word.withColumn(\"tipo_via\",\n",
    "# #                                         df_with_first_word[\"primera_palabra\"].rlike(\"^(clle?|cra)$\").cast(\"int\"))\n",
    "# temp = df_with_first_word.select(lower('primera_palabra')).distinct()\n",
    "# print(temp.count())\n",
    "# # Mostrar el DataFrame resultante\n",
    "# display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0058dd6a-fcd6-4a84-980b-461db5651519",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "###  Transformacion de Contacts  ###\n",
    "\n",
    "columnas = ['T_CONTACT_ID','CONTACT_NUMBER',\"FIRSTNAME\", \"LASTNAME\",\"ID_NUMBER\",\"BIRTHDATE\",\"EMAIL\",\"NAT_NUMBER_CELLPHONE\",\"GENDER\",\"ADDRESS_SALUTATION\",\"MAIN_ADDR_LINE1\",\"MAIN_ADDR_TOWN\",\"MAIN_ADDR_GEO_ZONE\",\"MAIN_ADDR_COUNTRY\",'IS_GUEST',\"CREATED_DATE\",'LAST_MODIFICATION_FROM','CREATED_FROM',\"LAST_UPDATE\",'LAST_MODIFICATION','MAIN_ADDR_ZIPCODE']\n",
    " \n",
    "### A) seleccion de columnas ###\n",
    "df_contacts = df_ini.select(columnas).\\\n",
    "    withColumn(\"EMAIL\", lower(\"EMAIL\")).\\\n",
    "    withColumn(\"MAIN_ADDR_LINE1\", lower(\"MAIN_ADDR_LINE1\")).\\\n",
    "    withColumn(\"BIRTHDATE\", to_timestamp(df_ini[\"BIRTHDATE\"], \"MM/dd/yyyy HH:mm:ss\")).\\\n",
    "    withColumn(\"BIRTHDATE\", to_date(\"BIRTHDATE\")).\\\n",
    "    withColumn(\"CREATED_DATE\", to_timestamp(df_ini[\"CREATED_DATE\"], \"MM/dd/yyyy HH:mm:ss\")).\\\n",
    "    withColumn(\"LAST_UPDATE\", to_timestamp(df_ini[\"LAST_UPDATE\"], \"MM/dd/yyyy HH:mm:ss\")).\\\n",
    "    withColumn(\"LAST_MODIFICATION\", to_timestamp(df_ini[\"LAST_MODIFICATION\"], \"MM/dd/yyyy HH:mm:ss\")).\\\n",
    "    withColumn(\"MAIN_ADDR_TOWN\", coalesce(df_ini[\"MAIN_ADDR_TOWN\"], df_ini[\"MAIN_ADDR_GEO_ZONE\"]))#.\\\n",
    "    #withColumn(\"MAIN_ADDR_LINE1_type\", split(df_ini[\"MAIN_ADDR_LINE1\"], \" \")[0])\n",
    "\n",
    "# ciudades con \"-SELECCIONAR-\", \"COLOMBIA\" pone el departamento\n",
    "df_contacts = df_contacts.withColumn(\"MAIN_ADDR_TOWN_\",\n",
    "                   when(df_contacts[\"MAIN_ADDR_TOWN\"].isin(\"-SELECCIONAR-\", \"COLOMBIA\"),\n",
    "                        df_contacts[\"MAIN_ADDR_GEO_ZONE\"]).otherwise(df_contacts[\"MAIN_ADDR_TOWN\"]))\n",
    "\n",
    "\n",
    "#df_contacts.printSchema()\n",
    "#display(df_contacts.limit(10))\n",
    "\n",
    "df_contacts.createOrReplaceTempView(\"df_contacts_vw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3546929b-de2c-4ea4-9223-4f15ae983a1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tmp = df_contacts.filter(col('MAIN_ADDR_TOWN').isin('-SELECCIONAR-','COLOMBIA'))\n",
    "# display(tmp.limit(100))\n",
    "\n",
    "# tmp = df_contacts.filter(year('LAST_MODIFICATION') == 2024).\\\n",
    "#     groupBy(\"MAIN_ADDR_TOWN_\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# tmp = df_contacts.select('T_CONTACT_ID','ID_NUMBER','MAIN_ADDR_LINE1','MAIN_ADDR_TOWN','MAIN_ADDR_TOWN_','MAIN_ADDR_COUNTRY','CREATED_DATE','LAST_UPDATE','LAST_MODIFICATION').\\\n",
    "#     filter((year('CREATED_DATE') == 2024) & (month('CREATED_DATE') == 4))\n",
    "# display(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96395748-2c4b-4aaf-86a8-110ac115d121",
     "showTitle": true,
     "title": "AJUSTE DIRECCION"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "\n",
    "###############################################\n",
    "####  FUNCION QUE AÑADE ESPACIOS\n",
    "\n",
    "# Define una función que aplica regexp_replace a una cadena\n",
    "def agregar_espacios_direccion(direccion):\n",
    "    if isinstance(direccion, str):  # Comprueba si la dirección es una cadena de texto\n",
    "        direccion_con_espacios = re.sub(r'(\\D)(?=\\d)', r'\\1 ', direccion)\n",
    "        direccion_con_espacios = re.sub(r'(\\d)(?=\\D)', r'\\1 ', direccion_con_espacios)\n",
    "        return direccion_con_espacios\n",
    "    else:\n",
    "        return direccion\n",
    "\n",
    "# Register User Defined Function (UDF) con Spark\n",
    "# udf: Es una función de PySpark que se utiliza para registrar una función definida por el usuario o UDF. Esta función toma dos argumentos: la función definida por el usuario y el tipo de datos de salida del UDF.\n",
    "# StringType() Especifica el tipo de datos de salida del UDF.\n",
    "# Si no registras tu función como un UDF, no podrás aplicarla directamente a una columna en un DataFrame de PySpark\n",
    "agregar_espacios_direccion = udf(agregar_espacios_direccion, StringType())\n",
    "\n",
    "\n",
    "################################################################\n",
    "####  FUNCION QUE MODIFICA VALORES DISTINTOS DE CALLE Y CARRERA\n",
    "\n",
    "# Función para convertir abreviaturas de direcciones\n",
    "def ajuste_calles_carreras(direccion):\n",
    "    if isinstance(direccion, str):  # Comprueba si la dirección es una cadena de texto\n",
    "        # Diccionario de mapeo de abreviaturas\n",
    "        mapeo_abreviaturas = {\n",
    "            \"cl\": \"calle\",\n",
    "            \"cle\": \"calle\",\n",
    "            \"cll\": \"calle\",\n",
    "            \"clle\": \"calle\",\n",
    "            \"call\": \"calle\",\n",
    "            \"calle\": \"calle\",\n",
    "            \"cr\": \"carrera\",\n",
    "            \"crr\": \"carrera\",\n",
    "            \"cra\": \"carrera\",\n",
    "            \"carrera\": \"carrera\",\n",
    "            \"kr\": \"carrera\",\n",
    "            \"tranv\": \"transversal\",\n",
    "            \"tr\": \"transversal\",\n",
    "            \"transversal\": \"transversal\",\n",
    "            \"av\": \"avenida\",\n",
    "            \"apto\": \"apartamento\",\n",
    "            \"apt\": \"apartamento\",\n",
    "            \"apartame\": \"apartamento\",\n",
    "            \"ap\": \"apartamento\",\n",
    "            \"int\": \"interior\",\n",
    "            \"interior\": \"interior\",\n",
    "            \"torre\": \"interior\",\n",
    "            \"no\": \"\",\n",
    "            \"n\": \"\",\n",
    "            \"numero\": \"\",\n",
    "            \"dg\": \"diagonal\",\n",
    "            \"diag\": \"diagonal\",\n",
    "\n",
    "            # Puedes agregar más abreviaturas según tus necesidades\n",
    "        }\n",
    "        # Separar la dirección en palabras\n",
    "        palabras = direccion.split()\n",
    "        # Reemplazar abreviaturas por sus equivalentes completos\n",
    "        palabras = [mapeo_abreviaturas.get(palabra.lower(), palabra) for palabra in palabras]\n",
    "        # Unir las palabras de nuevo en una cadena\n",
    "        return ' '.join(palabras)\n",
    "    else:\n",
    "        return direccion\n",
    "\n",
    "\n",
    "# Registra la función definida por el usuario como un UDF\n",
    "ajuste_calles_carreras = udf(ajuste_calles_carreras, StringType())\n",
    "\n",
    "\n",
    "################################################################\n",
    "####  FUNCION QUE ELIMINA CARACTERES ESPECIALES\n",
    "\n",
    "# Define la función para limpiar direcciones utilizando expresiones regulares\n",
    "def ajuste_caracteres_esp(direccion):\n",
    "    if isinstance(direccion, str):  # Comprueba si la dirección es una cadena de texto\n",
    "        # Elimina caracteres especiales\n",
    "        patron = r'[^\\w\\s]'\n",
    "        direccion = re.sub(patron, ' ', direccion)\n",
    "        # Quita los acentos o tildes\n",
    "        direccion_limpia = unidecode(direccion)\n",
    "        return direccion_limpia\n",
    "    else:\n",
    "        return direccion\n",
    "\n",
    "# Registra la función como un UDF\n",
    "ajuste_caracteres_esp = udf(ajuste_caracteres_esp, StringType())\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "####  FUNCION QUE ELIMINA TODO LO QUE SIGA DESPUES DE LAS PALABRAS EN EL PATRON\n",
    "\n",
    "def limpiar_torre_apto(direccion):\n",
    "    if isinstance(direccion, str):  # Comprueba si la dirección es una cadena de texto\n",
    "        # Expresión regular para encontrar las palabras clave y todo lo que esté después de ellas\n",
    "        patron = r'\\b(barrio|apartamento|interior|anillo|piso)\\b.*'\n",
    "        # Elimina todo lo que está después de las palabras clave\n",
    "        direccion_limpia = re.sub(patron, '', direccion)\n",
    "        # Elimina los espacios adicionales al final de la cadena resultante\n",
    "        direccion_limpia = direccion_limpia.strip()\n",
    "        return direccion_limpia\n",
    "    else:\n",
    "        return direccion\n",
    "\n",
    "# Registra la función como un UDF\n",
    "limpiar_torre_apto = udf(limpiar_torre_apto, StringType())\n",
    "\n",
    "#################################################################################\n",
    "####  FUNCION QUE SEPARA NUMEROS DE 4 O MAS DIGITOS EN SUS VALORES MEDIOS\n",
    "# Ej: 6292 quedaria 62 92\n",
    "def separar_numeros(direccion):\n",
    "    if isinstance(direccion, str):  # Comprueba si la dirección es una cadena de texto\n",
    "        # Encuentra todos los números de 4 dígitos en la dirección\n",
    "        numeros = re.findall(r'\\b\\d{4}\\b', direccion)\n",
    "        # Divide cada número por la mitad y lo reformatea como \"XX YY\"\n",
    "        numeros_separados = [numero[:2] + ' ' + numero[2:] for numero in numeros]\n",
    "        # Reemplaza los números originales en la dirección con los números separados\n",
    "        for numero in numeros:\n",
    "            direccion = direccion.replace(numero, numeros_separados[numeros.index(numero)], 1)\n",
    "        return direccion\n",
    "    else:\n",
    "        return direccion\n",
    "\n",
    "# Registra la función como un UDF\n",
    "separar_numeros = udf(separar_numeros, StringType())\n",
    "\n",
    "\n",
    "\n",
    "# Aplicamos las funciones creadas\n",
    "df_contacts = df_contacts.withColumn(\"Direccion_new\", ajuste_caracteres_esp(\"MAIN_ADDR_LINE1\")).\\\n",
    "    withColumn(\"Direccion_new\", agregar_espacios_direccion(col('Direccion_new'))).\\\n",
    "    withColumn(\"Direccion_new\", ajuste_calles_carreras(col(\"Direccion_new\"))).\\\n",
    "    withColumn(\"Direccion_new\", limpiar_torre_apto(col(\"Direccion_new\"))).\\\n",
    "    withColumn(\"Direccion_new\", separar_numeros(col(\"Direccion_new\")))\n",
    "    \n",
    "\n",
    "#display(df_contacts.limit(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67593790-cc50-4669-a833-69c7ac307678",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# temp = df_contacts.select('MAIN_ADDR_LINE1','Direccion_new').distinct()\n",
    "# #print(temp.count())\n",
    "# display(temp.limit(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6014775-ef7b-40f6-9d5f-af2410eb4ec1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tmp = df_contacts.filter(col('MAIN_ADDR_TOWN').isin('-SELECCIONAR-','COLOMBIA'))\n",
    "# display(tmp.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6fcc231-eb1c-4726-8a06-64e9d5eba375",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tmp = df_contacts.filter(year('LAST_MODIFICATION') == 2024).\\\n",
    "#     groupBy(\"MAIN_ADDR_TOWN_\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# display(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "761d0dc0-2f94-4a50-b887-aa89d22fa9e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#temp = df_ini.filter(col('T_CONTACT_ID') == '10229527487512')#LAST_MODIFICATION\n",
    "# temp = df_ini.filter(col(year('LAST_UPDATE')) == 2024)\n",
    "# display(temp.limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8229e09-c8d7-4c89-804c-0ca8afdf4ddd",
     "showTitle": true,
     "title": "AJUSTE CIUDAD CLIENTE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MAIN_ADDR_TOWN_    count\n",
      "0            None  1421197\n",
      "1          BOGOTA   623072\n",
      "2     BOGOTÁ D.C.   248772\n",
      "3          BOGOTÁ   113745\n",
      "4    BARRANQUILLA   112711\n"
     ]
    }
   ],
   "source": [
    "# Creamos la maestra de valores modificados\n",
    "#df_contacts_dirty = df_contacts.filter(df_spark[\"MAIN_ADDR_COUNTRY\"].isin(\"valor_deseado\") )\n",
    "dirty_cities = df_contacts.groupBy(\"MAIN_ADDR_TOWN_\").count().orderBy(col(\"count\").desc())#.\\\n",
    "    #filter(col('MAIN_ADDR_TOWN_') == lit('Tolima'))\n",
    "\n",
    "inpath = \"abfss://storagebi@tbdwhstorage01.dfs.core.windows.net/Modelos_analitica/Maestras_municipios/\"\n",
    "\n",
    "write_table = dirty_cities.coalesce(1) # coalesce indica que la tabla se va a entregar en una sola particion\n",
    "write_table.write.csv(inpath + \"dirty_cities\", header=True, mode=\"overwrite\", sep='|')\n",
    "\n",
    "#cambio de nombre\n",
    "files=dbutils.fs.ls(inpath + 'dirty_cities/')\n",
    "output_file= [x for x in files if x.name.startswith(\"part-\")]\n",
    "\n",
    "# EN la misma carpeta de origen\n",
    "dbutils.fs.mv(output_file[0].path, f\"{inpath + 'dirty_cities/'}/dirty_cities.csv\")\n",
    "\n",
    "#dirty_cities.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").option(\"sep\", \"|\").save(inpath + \"dirty_cities.csv\")\n",
    "#dirty_cities.write.csv(inpath + \"dirty_cities.csv\", header=True, mode=\"overwrite\", sep='|')\n",
    "dirty_cities = dirty_cities.toPandas()\n",
    "\n",
    "#display(dirty_cities.limit(10))\n",
    "print(dirty_cities.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05bd94fa-1942-4776-97ec-38d47d1e49c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681\n",
      "1044\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "####  LECTURA DE CSV's REQUERIDOS  ###\n",
    "\n",
    "## Codigos postales\n",
    "codpost = spark.read.csv(inpath + 'codpost.csv', sep = '|', header=True, inferSchema=True)\n",
    "print(codpost.count())\n",
    "codpost = codpost.toPandas()\n",
    "#print(codpost.head(5))\n",
    "\n",
    "\n",
    "## maestra de municipios de Colombia\n",
    "dim_towns = spark.read.csv(inpath + 'dim_municipios.csv', sep = '|', header=True, inferSchema=True)\n",
    "print(dim_towns.count())\n",
    "dim_towns = dim_towns.toPandas()\n",
    "#print(dim_towns.head(5))\n",
    "\n",
    "\n",
    "## localidades de Bogota\n",
    "loc_bog = spark.read.csv(inpath + 'localidades_bogota.csv', sep = '|', header=True, inferSchema=True)\n",
    "print(loc_bog.count())\n",
    "loc_bog = loc_bog.toPandas()\n",
    "#print(loc_bog.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c1b5fd-ac63-49e0-87a4-6f2e8a3009ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "####  FUNCIONES  ####\n",
    "\n",
    "# Limpieza de texto\n",
    "def limpiar_texto(texto):\n",
    "    if texto is None:\n",
    "        return 'Sin Registro'\n",
    "    \n",
    "    # Mayuscula\n",
    "    texto_mayus = str.upper(texto)\n",
    "\n",
    "    # Eliminar valores numéricos utilizando expresiones regulares\n",
    "    texto_sin_numeros = re.sub(r'\\d+', '', str(texto_mayus))\n",
    "\n",
    "    # Remover tildes y caracteres especiales de entonacion\n",
    "    texto_sin_tildes = unidecode(texto_sin_numeros)\n",
    "    #texto_sin_tildes = unidecode(texto)\n",
    "\n",
    "    # Quitar caracteres no alfabéticos y no espacios en blanco\n",
    "    texto_limpio = re.sub(r'[^a-zA-Z\\s]', '', texto_sin_tildes)\n",
    "\n",
    "    # Aplicar trim para eliminar espacios en blanco al principio y al final\n",
    "    texto_limpio = texto_limpio.strip()\n",
    "    \n",
    "    return texto_limpio\n",
    "\n",
    "\n",
    "# Funcion like ampliada\n",
    "def asignar_ciudad(row):\n",
    "    # el diccionario se usa para buscar una coincidencia parcial entre las claves y los valores en la columna\n",
    "    condiciones = {\n",
    "        'BOGO': 'BOGOTA',\n",
    "        'GOTA': 'BOGOTA',\n",
    "        'LOCALID': 'BOGOTA',\n",
    "        'MEDEL': 'MEDELLIN',\n",
    "        'COMUNA': 'MEDELLIN',\n",
    "        'POBLAD': 'MEDELLIN',\n",
    "        'CALIFORNIA': 'SACRAMENTO',\n",
    "        'MEXICALI': 'MEXICALI',\n",
    "        'CALI': 'CALI',\n",
    "        'DUPAR': 'VALLEDUPAR',\n",
    "        'VALLE': 'CALI',\n",
    "        'CARTAGE': 'CARTAGENA',\n",
    "        'QUILLA': 'BARRANQUILLA',\n",
    "        'BARRANQ': 'BARRANQUILLA',\n",
    "        'VILLAVI': 'VILLAVICENCIO',\n",
    "        'YOPAL': 'YOPAL',\n",
    "        'YPAL': 'YOPAL',\n",
    "        'TUNJA': 'TUNJA',\n",
    "        'CUCUT': 'CUCUTA',\n",
    "        'MANIZA': 'MANIZALES',\n",
    "        'IBAG': 'IBAGUE',\n",
    "        'NEIV': 'NEIVA', \n",
    "        'MARTA': 'SANTA MARTA',\n",
    "        'BUCARA': 'BUCARAMANGA',\n",
    "        'MONTERI': 'MONTERIA',\n",
    "        'POPAYA': 'POPAYAN',\n",
    "        'ARMENI': 'ARMENIA',\n",
    "        'PEREIR': 'PEREIRA',\n",
    "        'UBATE': 'UBATE',\n",
    "        'CHIA': 'CHIA',\n",
    "        'SOLEDA': 'SOLEDAD',\n",
    "        'BELLO': 'BELLO',\n",
    "        'SOACH': 'SOACHA',\n",
    "        'BUGA': 'BUGA',\n",
    "        'PAST': 'PASTO',\n",
    "        'MANGA': 'BUCARAMANGA',\n",
    "        'SOGAMO': 'SOGAMOSO',\n",
    "        'DUITA': 'DUITAMA',\n",
    "        # Puedes agregar más condiciones aquí según sea necesario\n",
    "    }\n",
    "    \n",
    "    for condicion, ciudad in condiciones.items():\n",
    "        if condicion in row:\n",
    "            return ciudad\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "# Elimina la palabra que pertenezca a la lista\n",
    "def eliminar_departamento(row):\n",
    "    regiones = ['AMAZONAS','ANTIOQUIA', 'ARAUCA','ATLANTICO','BOLIVAR','BOYACA','CALDAS','CAQUETA',\n",
    "                'CASANARE','CAUCA','CESAR','CHOCO','CUNDINAMARCA','CORDOBA','GUAINIA','GUAVIARE','HUILA',\n",
    "                'LA GUAJIRA','MAGDALENA','META','NARINO','NORTE DE SANTANDER','PUTUMAYO','QUINDIO',\n",
    "                'RISARALDA','ISLA','ISLAS','SANTANDER','SUCRE','TOLIMA','VALLE DEL CAUCA','VAUPES','VICHADA']\n",
    "\n",
    "    # Crear un diccionario donde las claves sean los valores de la lista y los valores sean None\n",
    "    dic= {region: '' for region in regiones}\n",
    "    \n",
    "    for condicion, ciudad in dic.items():\n",
    "        if condicion in row:\n",
    "            row = row.replace(condicion, ciudad).strip()\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "# Reemplaza algunas versiones adicionales de ciudad\n",
    "def replace_cities_aliases(ciudad):\n",
    "    # bogota_aliases = ['BOOGOTA','BTA','BOGTA','BOG','BOOGTA','BGTA','BGOTA','BGA','CUNDINAMARCA','BGOOTA','BOOTA',\n",
    "    #                   'BIGOTA','BOGITA','CEDRITOS','BOBOTA','B OGOTA','BOGATA','BOHOTA','BOGPTA',]\n",
    "    bogota_aliases = ['BOTOTA','BTA','BOGTA','BOG','BOOGTA','BGTA','KENEDY','BGA','CUNDINAMARCA','BGOOTA','BOOTA','BOFOTA','BOGITA','CEDRITOS','BOBOTA','NOGOTA','BOGATA','BOHOTA','BOGPTA','CIUDAD VERDE','CIUDADVERDE','TINTAL','HAYUELOS','SALITRE']\n",
    "    barranquilla_aliases = ['ATLANTICO','BAQ','BQLLLA','BQ','BQA','BQLLA','BARRAQNUILLA','BARRANUILLA','BQUILLLA']\n",
    "    cali_aliases = ['VALLE DEL CAUCA']\n",
    "    cartagena_aliases = ['CTG']\n",
    "    ibague_aliases = ['IABGUE']\n",
    "    medellin_aliases = ['ANTIOQUIA','POBLADO','MED','MDELLIN','RIO NEGRO']\n",
    "    santanderdequilichao = ['DE QUILICHAO']\n",
    "    if ciudad in bogota_aliases:\n",
    "        return 'BOGOTA'\n",
    "    elif ciudad in barranquilla_aliases:\n",
    "        return 'BARRANQUILLA'\n",
    "    elif ciudad in cali_aliases:\n",
    "        return 'CALI'\n",
    "    elif ciudad in cartagena_aliases:\n",
    "        return 'CARTAGENA'\n",
    "    elif ciudad in medellin_aliases:\n",
    "        return 'MEDELLIN'\n",
    "    elif ciudad in ibague_aliases:\n",
    "        return 'IBAGUE'\n",
    "    elif ciudad in santanderdequilichao:\n",
    "        return 'SANTANDER DE QUILICHAO'\n",
    "    else:\n",
    "        return ciudad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1215607e-730a-4a95-8bc0-8391840982c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIN_ADDR_TOWN_    36867\n",
      "count              36868\n",
      "Codigo Postal        531\n",
      "Ciudad             36867\n",
      "dtype: int64\n",
      "[None 'BOGOTA' 'BOGOTÁ D.C.' ... 'EL RUBY' 'CUCUTA/LOS PATIOS '\n",
      " ' WASHINGTON D. C.,VAIL']\n"
     ]
    }
   ],
   "source": [
    "## Transformacion 1: Codigos postales\n",
    "\n",
    "# left join de dirty_cities con codigo postal\n",
    "cities_ = pd.merge(dirty_cities, codpost[['Codigo Postal', 'Ciudad']],\\\n",
    "                          left_on='MAIN_ADDR_TOWN_', right_on= codpost['Codigo Postal'].astype(str),\\\n",
    "                          how='left')\n",
    "\n",
    "# Rellenar los valores nulos en 'Ciudad' con los valores de 'MAIN_ADDR_TOWN'\n",
    "cities_['Ciudad'].fillna(cities_['MAIN_ADDR_TOWN_'], inplace=True)\n",
    "\n",
    "print(cities_.count())\n",
    "print(cities_['Ciudad'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca045811-ca06-40ce-8f19-2d5290ec14dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tmp = cities_['Ciudad'].unique()\n",
    "# tmp = spark.createDataFrame(tmp)\n",
    "\n",
    "# display(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f8e678-6397-479d-ac63-7ee201b48ffd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              MAIN_ADDR_TOWN_    COUNT  ...  LOCALIDAD              CIUDAD\n",
      "0                        None  1421197  ...        NaN        Sin Registro\n",
      "1                      BOGOTA   623072  ...        NaN              BOGOTA\n",
      "2                 BOGOTÁ D.C.   248772  ...        NaN              BOGOTA\n",
      "3                      BOGOTÁ   113745  ...        NaN              BOGOTA\n",
      "4                BARRANQUILLA   112711  ...        NaN        BARRANQUILLA\n",
      "...                       ...      ...  ...        ...                 ...\n",
      "36863   URB NORMANDIA/SOLEDAD        1  ...        NaN             SOLEDAD\n",
      "36864                   GOREY        1  ...        NaN               GOREY\n",
      "36865              Ruefenacht        1  ...        NaN          RUEFENACHT\n",
      "36866             SCARRINGTON        1  ...        NaN         SCARRINGTON\n",
      "36867   WASHINGTON D. C.,VAIL        1  ...        NaN  WASHINGTON D CVAIL\n",
      "\n",
      "[36868 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "## Transformacion 2: limpieza de texto y join con localidades bogota\n",
    "\n",
    "total = sum(cities_['count'])\n",
    "#print('num registros: ', total)\n",
    "\n",
    "# Limpieza del campo ciudad de acuerdo con la funcion limpiar_texto\n",
    "dim_municipios_ = cities_.sort_values(by='count', ascending=False).\\\n",
    "       assign(Ciudad = lambda x: x['Ciudad'].apply(limpiar_texto),\n",
    "              PARTICIPACION = lambda x: x['count']/total,\n",
    "              TOTAL = lambda x: np.cumsum(x['PARTICIPACION'])).\\\n",
    "       rename(columns = {'count': 'COUNT'})\n",
    "       #groupby('DEPARTAMENTO').agg({'COUNT': 'sum','PORCENTAJE': 'sum'}).reset_index().\\\n",
    "\n",
    "\n",
    "# left join con localidades\n",
    "dim_municipios_1 = pd.merge(dim_municipios_, loc_bog,\\\n",
    "                          left_on='Ciudad', right_on= 'LOCALIDAD',\\\n",
    "                          how='left')\n",
    "\n",
    "# Rellenar los valores nulos en 'CIUDAD' (de loc_bog)con los valores de 'Ciudad'\n",
    "dim_municipios_1 = dim_municipios_1.assign(CIUDAD = lambda x: x['CIUDAD'].fillna(dim_municipios_1['Ciudad'])).\\\n",
    "                                    assign(CIUDAD = lambda x: x['CIUDAD'].apply(asignar_ciudad)).\\\n",
    "                                    assign(CIUDAD = lambda x: x['CIUDAD'].apply(replace_cities_aliases))\n",
    "\n",
    "print(dim_municipios_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa28c98d-bf0c-4575-92d8-cf76f8ff210e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              MAIN_ADDR_TOWN_    COUNT  PARTICIPACION              CIUDAD\n",
      "0                        None  1421197   3.719936e-01        Sin Registro\n",
      "1                      BOGOTA   623072   1.630870e-01              BOGOTA\n",
      "2                 BOGOTÁ D.C.   248772   6.511524e-02              BOGOTA\n",
      "3                      BOGOTÁ   113745   2.977237e-02              BOGOTA\n",
      "4                BARRANQUILLA   112711   2.950173e-02        BARRANQUILLA\n",
      "...                       ...      ...            ...                 ...\n",
      "36863   URB NORMANDIA/SOLEDAD        1   2.617467e-07             SOLEDAD\n",
      "36864                   GOREY        1   2.617467e-07               GOREY\n",
      "36865              Ruefenacht        1   2.617467e-07          RUEFENACHT\n",
      "36866             SCARRINGTON        1   2.617467e-07         SCARRINGTON\n",
      "36867   WASHINGTON D. C.,VAIL        1   2.617467e-07  WASHINGTON D CVAIL\n",
      "\n",
      "[36868 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## Transformacion 3:  llave departamento para traer capital a los que tienen departamento en el campo ciudad\n",
    "dim_regiones = dim_towns[['DEPARTAMENTO','CAPITAL']].drop_duplicates()\n",
    "#print(dim_regiones)\n",
    "\n",
    "dim_municipios = pd.merge(dim_municipios_1, dim_regiones,\\\n",
    "                          left_on='CIUDAD', right_on= 'DEPARTAMENTO',\\\n",
    "                          how='left')\n",
    "\n",
    "# Rellenar los valores nulos en 'Ciudad' con los valores de 'MAIN_ADDR_TOWN'\n",
    "dim_municipios['CAPITAL'].fillna(dim_municipios['CIUDAD'], inplace=True)\n",
    "\n",
    "# Finalmente seleccionamos los campos necesarios\n",
    "dim_municipios = dim_municipios[['MAIN_ADDR_TOWN_','COUNT','PARTICIPACION','CAPITAL']]\n",
    "\n",
    "dim_municipios.rename(columns={'CAPITAL': 'CIUDAD'}, inplace=True)\n",
    "\n",
    "print(dim_municipios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7290f95-fc3e-4f26-b95a-47b1c0ecc9bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Transformacion 4:  left join para validar cuales valores quedaron limpios y traer la region y el departamento\n",
    "dim_municipios = pd.merge(dim_municipios, dim_towns,\\\n",
    "                          left_on='CIUDAD', right_on= 'MUNICIPIO',\\\n",
    "                          how='left')\n",
    "\n",
    "# Traer los valores que ya sabiamos eran nulos o ''\n",
    "dim_municipios['MUNICIPIO'] = np.where(\n",
    "    (dim_municipios['CIUDAD'] == '') |\n",
    "    (dim_municipios['CIUDAD'] == 'nan') |\n",
    "    (dim_municipios['CIUDAD'] == 'None') |\n",
    "    (dim_municipios['CIUDAD'].isnull()),\n",
    "    None,\n",
    "    dim_municipios['MUNICIPIO']\n",
    ")\n",
    "#print(dim_municipios.head(5))\n",
    "\n",
    "# Valores con municipio matched\n",
    "# prueba = dim_municipios[dim_municipios['MUNICIPIO'].notnull()]\n",
    "\n",
    "\n",
    "# print('Registros: ', prueba['COUNT'].sum())\n",
    "# print('Percent: ', prueba['PARTICIPACION'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f4396eb-6ec3-4391-8ed9-a1c5af34ae38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros:  2289952\n",
      "Percent:  0.5993873034020785\n",
      "(11161, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Finalmente seleccionamos los campos necesarios\n",
    "dim_municipios = dim_municipios[['MAIN_ADDR_TOWN_','COUNT','PARTICIPACION','CIUDAD','MUNICIPIO','REGION','DEPARTAMENTO','CAPITAL','PAIS']]\n",
    "\n",
    "# Valores con MUNICIPIO LIMPIO\n",
    "notnull = dim_municipios[dim_municipios['MUNICIPIO'].notnull()]\n",
    "\n",
    "print('Registros: ', notnull['COUNT'].sum())\n",
    "print('Percent: ', notnull['PARTICIPACION'].sum())\n",
    "\n",
    "#################\n",
    "# Descriptivos\n",
    "# print(notnull.head(5))\n",
    "# print(' ')\n",
    "# print('Dimensiones:')\n",
    "print(notnull.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09198ecd-b409-4468-abd7-31c4d2a6105e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros:  1530536\n",
      "Percent:  0.40061269659792137\n",
      "Dimensiones:\n",
      "(25707, 9)\n"
     ]
    }
   ],
   "source": [
    "# Valores con MUNICIPIO sin limpiar\n",
    "null = dim_municipios[dim_municipios['MUNICIPIO'].isnull()]\n",
    "\n",
    "print('Registros: ', null['COUNT'].sum())\n",
    "print('Percent: ', null['PARTICIPACION'].sum())\n",
    "\n",
    "#################\n",
    "# Descriptivos\n",
    "print('Dimensiones:')\n",
    "print(null.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d44a9d9-6e49-403b-9696-4b4f0ac31db2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Convertir el DataFrame de Pandas a un DataFrame de PySpark\n",
    "# dim_municipios_ = spark.createDataFrame(dim_municipios)\n",
    "\n",
    "# tmp = dim_municipios_.groupBy(\"MUNICIPIO\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "# #display(contacts_silver.limit(100))\n",
    "# display(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3b0bc45-34d9-415b-a76e-e07cd058a142",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros:  9772\n",
      "Percent:  0.0025577884291221437\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la funcion de eliminar departamento para limpiar valores estilo: 'ABEJORRAL ANTIOQUIA'\n",
    "null = null[['MAIN_ADDR_TOWN_','COUNT','PARTICIPACION','CIUDAD']].\\\n",
    "    assign(CIUDAD = lambda x: x['CIUDAD'].apply(eliminar_departamento))\n",
    "\n",
    "\n",
    "\n",
    "# left join para traer la region y el departamento NUEVAMENTE\n",
    "null = pd.merge(null, dim_towns,\\\n",
    "                    left_on='CIUDAD', right_on= 'MUNICIPIO',\\\n",
    "                    how='left')\n",
    "\n",
    "null2 = null[null['MUNICIPIO'].notnull()]\n",
    "\n",
    "print('Registros: ', null2['COUNT'].sum())\n",
    "print('Percent: ', null2['PARTICIPACION'].sum())\n",
    "\n",
    "# #################\n",
    "# # Descriptivos\n",
    "# print('Dimensiones:')\n",
    "# print(null2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9adc818-a9e7-4d23-9419-f4e9a2290c46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# UNIMOS AMBAS TABLAS PARA TENER LA LIMPIEZA COMPLETA\n",
    "dim_municipios_ = pd.concat([notnull, null2])\n",
    "\n",
    "# Rellenar los valores nulos en 'Ciudad' con los valores de 'MAIN_ADDR_TOWN'\n",
    "#dim_municipios_['Ciudad'].fillna(cities_['MAIN_ADDR_TOWN'], inplace=True)\n",
    "\n",
    "# Convertir el DataFrame de Pandas a un DataFrame de PySpark\n",
    "dim_municipios_ = spark.createDataFrame(dim_municipios_)\n",
    "#display(dim_municipios_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c48f356b-e3f0-4778-a3ec-299ae9f780a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#prueba = dim_municipios.groupBy(\"MAIN_ADDR_TOWN\").count().orderBy(F.col(\"count\").desc())\n",
    "#display(prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cbaa2c5-4d20-4eab-a9ca-4383918645ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3820488\n"
     ]
    }
   ],
   "source": [
    "### TABLA SILVER CONTACTS\n",
    "\n",
    "# Pasamos a vista la tabla Contacts y la maestra dim_municipios\n",
    "df_contacts.createOrReplaceTempView(\"df_contacts_vw\")\n",
    "dim_municipios_.createOrReplaceTempView(\"dim_municipios_vw\")\n",
    "\n",
    "# se hacen las transformaciones finales\n",
    "contacts_silver = spark.sql(\"\"\"\n",
    "    select \n",
    "\t    c.T_CONTACT_ID,\n",
    "      c.CONTACT_NUMBER,\n",
    "      c.FIRSTNAME, \n",
    "      c.LASTNAME,\n",
    "      c.ID_NUMBER,\n",
    "      c.BIRTHDATE as FECHA_DE_NACIMIENTO,\n",
    "      -- Obtiene la edad en años basada en la diferencia entre la fecha actual y la fecha de nacimiento\n",
    "      CASE \n",
    "            WHEN c.BIRTHDATE IS NULL THEN NULL\n",
    "            ELSE FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12)\n",
    "        END AS Edad,\n",
    "        CASE \n",
    "            WHEN FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12) IS NULL THEN 'SIN DATO'\n",
    "            WHEN FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12) < 18 THEN 'Menor de 18'\n",
    "            WHEN FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12) <= 24 THEN '18 a 24'\n",
    "            WHEN FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12) <= 34 THEN '25 a 34'\n",
    "            WHEN FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12) <= 44 THEN '35 a 44'\n",
    "            WHEN FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12) <= 54 THEN '45 a 54'\n",
    "            WHEN FLOOR(DATEDIFF(MONTH, c.BIRTHDATE, GETDATE()) / 12) <= 64 THEN '55 a 64'\n",
    "            ELSE 'Mayor a 64'\n",
    "        END AS Rango_de_edad,\n",
    "      c.EMAIL,\n",
    "      c.NAT_NUMBER_CELLPHONE,\n",
    "      CASE \n",
    "            WHEN c.GENDER = 'MALE' THEN 'HOMBRE'\n",
    "            WHEN c.GENDER = 'FEMALE' THEN 'MUJER'\n",
    "            WHEN c.GENDER = 'UNKNOWN' AND c.ADDRESS_SALUTATION IN ('Mr', 'Señor', 'Señor,', 'Don') THEN 'HOMBRE'\n",
    "            WHEN c.GENDER = 'UNKNOWN' AND c.ADDRESS_SALUTATION IN ('Ms','Mrs', 'Miss', 'Señora', 'Señorita') THEN 'MUJER'\n",
    "            WHEN c.GENDER = '' AND c.ADDRESS_SALUTATION IN ('Mr', 'Señor', 'Señor,', 'Don') THEN 'HOMBRE'\n",
    "            WHEN c.GENDER = '' AND c.ADDRESS_SALUTATION IN ('Ms','Mrs', 'Miss', 'Señora', 'Señorita') THEN 'MUJER'\n",
    "            WHEN COALESCE(c.GENDER, '') = '' AND c.ADDRESS_SALUTATION IN ('Mr', 'Señor', 'Señor,', 'Don') THEN 'HOMBRE'\n",
    "            WHEN COALESCE(c.GENDER, '') = '' AND c.ADDRESS_SALUTATION IN ('Ms','Mrs', 'Miss', 'Señora', 'Señorita') THEN 'MUJER'\n",
    "            WHEN c.GENDER IS NULL AND c.ADDRESS_SALUTATION IN ('Mr', 'Señor', 'Señor,', 'Don') THEN 'HOMBRE'\n",
    "            WHEN c.GENDER IS NULL AND c.ADDRESS_SALUTATION IN ('Ms','Mrs', 'Miss', 'Señora', 'Señorita') THEN 'MUJER'\n",
    "            ELSE 'SIN DATO'\n",
    "        END AS Genero,\n",
    "      c.ADDRESS_SALUTATION,\n",
    "      c.MAIN_ADDR_LINE1,\n",
    "      CONCAT(c.Direccion_new,', ',CASE \n",
    "            WHEN m.MUNICIPIO IS NULL THEN lower(c.MAIN_ADDR_TOWN_)\n",
    "            ELSE lower(m.MUNICIPIO)\n",
    "        END) AS Direccion_new,\n",
    "      c.IS_GUEST,\n",
    "      c.CREATED_DATE,\n",
    "      c.LAST_UPDATE,\n",
    "      c.LAST_MODIFICATION_FROM,\n",
    "      c.CREATED_FROM,\n",
    "      c.MAIN_ADDR_ZIPCODE,\n",
    "      c.MAIN_ADDR_TOWN,\n",
    "      c.MAIN_ADDR_GEO_ZONE,\n",
    "      c.MAIN_ADDR_COUNTRY,\n",
    "      c.MAIN_ADDR_TOWN_,\n",
    "      CASE \n",
    "            WHEN m.MUNICIPIO IS NULL THEN c.MAIN_ADDR_TOWN_\n",
    "            ELSE m.MUNICIPIO\n",
    "        END AS CIUDAD,\n",
    "      m.REGION,\n",
    "      m.DEPARTAMENTO,\n",
    "      m.CAPITAL,\n",
    "      CASE \n",
    "            WHEN m.PAIS  IS NULL THEN c.MAIN_ADDR_COUNTRY\n",
    "            ELSE m.PAIS\n",
    "        END AS PAIS\n",
    "    from df_contacts_vw c\n",
    "    left join dim_municipios_vw m\n",
    "      ON c.MAIN_ADDR_TOWN_ = m.MAIN_ADDR_TOWN_\n",
    "    order by T_CONTACT_ID \n",
    "\"\"\") \n",
    "\n",
    "# Realizar el left join entre los DataFrames df1 y df2\n",
    "#contacts_silver = df_contacts.join(dim_municipios, df_contacts['MAIN_ADDR_TOWN'] == dim_municipios['MAIN_ADDR_TOWN'], how='left')\n",
    "\n",
    "print(contacts_silver.count())\n",
    "#display(contacts_silver.limit(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45516c01-499d-4841-964f-f05f42c4bc9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tmp = contacts_silver.filter(col('MAIN_ADDR_TOWN').isin('-SELECCIONAR-','COLOMBIA'))\n",
    "#display(contacts_silver.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba4eec39-5846-422b-829b-adf7efde2a25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#modificar colombia, seleccionar\n",
    "#contacts_silver = contacts_silver.withColumn(\"CIUDAD\", when(col(\"CIUDAD\") == \"-SELECCIONAR-\", \"Sin Registro\").#otherwise(df[\"columna_a_reemplazar\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e760cc8-b70f-4628-90b4-9cbb0f6eae6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guarda el DataFrame en formato Parquet en Azure Blob Storage\n",
    "inpath = \"abfss://storagebi@tbdwhstorage01.dfs.core.windows.net/silver/Contacts/\"\n",
    "write_table = contacts_silver.coalesce(1) # coalesce indica que la tabla se va a entregar en una sola particion\n",
    "write_table.write.mode(\"overwrite\").parquet(inpath)\n",
    "\n",
    "#cambio de nombre\n",
    "files=dbutils.fs.ls(inpath)\n",
    "output_file= [x for x in files if x.name.startswith(\"part-\")]\n",
    " \n",
    "# EN la misma carpeta de origen\n",
    "dbutils.fs.mv(output_file[0].path, f\"{inpath}/Ds_S_Contacts.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb03208-64f6-4cfa-9bc6-5849e889e45e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Prueba para clientes nuevos ultimos 15 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64abf530-8904-4666-96b2-08cd7b4730a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col, current_date, date_sub\n",
    "\n",
    "# # Calcular la fecha hace 15 días\n",
    "# fecha_limite = date_sub(current_date(), 15)\n",
    "\n",
    "# # Filtrar los registros de los últimos 15 días\n",
    "# contacts_ultimos_15_dias = contacts_silver.filter(col(\"CREATED_DATE\") >= fecha_limite)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_Contacts",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
