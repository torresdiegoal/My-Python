{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_24664\\3901433779.py:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  \"SERVER=ADRIANAC\\SQLEXPRESS;\" #Nombre o direccion IP del SQL server\n"
     ]
    }
   ],
   "source": [
    "#Conexion a la base de datos AdventureWorks en SQL Server database\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "connection_string = (\n",
    "    \"DRIVER={ODBC Driver 17 for SQL Server};\"  # O el driver que tengas instalado\n",
    "    \"SERVER=ADRIANAC\\SQLEXPRESS;\" #Nombre o direccion IP del SQL server\n",
    "    \"DATABASE=AdventureWorks2022;\" #Nombre de la base de datos que tenog en SQL y quiero usar\n",
    "    \"Trusted_Connection=yes;\" #Porque tengo autenticacion de windows, sino, me pediria usuario y psw\n",
    ")\n",
    "\n",
    "# Establecer la conexión\n",
    "with pyodbc.connect(connection_string) as conn:\n",
    "    # Crear el cursor\n",
    "    cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| FirstName   | LastName    | MiddleName   | NumDuplicados   |\n",
      "|:------------|:------------|:-------------|:----------------|\n",
      "| Kim         | Abercrombie |              | 2               |\n",
      "| Kim         | Akers       |              | 3               |\n",
      "| Michael     | Allen       |              | 3               |\n",
      "| Gary        | Altman      | E.           | 2               |\n",
      "| Chris       | Ashton      |              | 2               |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_24664\\1310748788.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "#Identifica y elimina los registros duplicados de la tabla Person.Person.\n",
    "\n",
    "#Primero realizamos la consulta para identificar los duplicados que tengamos\n",
    "query = \"\"\"\n",
    "SELECT FirstName, LastName, MiddleName, COUNT(*) AS NumDuplicados\n",
    "FROM Person.Person\n",
    "GROUP BY FirstName, LastName, MiddleName\n",
    "HAVING COUNT(*) > 1;\n",
    "\"\"\"\n",
    "# Imprimir la consulta\n",
    "#print(query)\n",
    "# Leer datos en un DataFrame de Pandas\n",
    "df = pd.read_sql(query, conn)\n",
    "# Mostrar las primeras filas\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| BusinessEntityID   | PersonType   | NameStyle   | Title   | FirstName   | MiddleName   | LastName   | Suffix   | EmailPromotion   | AdditionalContactInfo   | Demographics                                                                                                                                                                  | rowguid                              | ModifiedDate        |\n",
      "|:-------------------|:-------------|:------------|:--------|:------------|:-------------|:-----------|:---------|:-----------------|:------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------|:--------------------|\n",
      "| 343                | SC           | False       | Mr.     | Michael     |              | Allen      |          | 2                |                         | <IndividualSurvey xmlns=\"http://schemas.microsoft.com/sqlserver/2004/07/adventure-works/IndividualSurvey\"><TotalPurchaseYTD>-15764.8128</TotalPurchaseYTD></IndividualSurvey> | FA93C578-2A25-4820-AA5D-E2437CC24C59 | 2011-07-01 00:00:00 |\n",
      "| 2374               | GC           | False       |         | Michael     |              | Allen      |          | 0                |                         | <IndividualSurvey xmlns=\"http://schemas.microsoft.com/sqlserver/2004/07/adventure-works/IndividualSurvey\"><TotalPurchaseYTD>0</TotalPurchaseYTD></IndividualSurvey>           | 8B91550B-9DB8-4D10-BBF6-03BA6CE65EC9 | 2008-12-19 00:00:00 |\n",
      "| 2375               | GC           | False       |         | Michael     |              | Allen      |          | 2                |                         | <IndividualSurvey xmlns=\"http://schemas.microsoft.com/sqlserver/2004/07/adventure-works/IndividualSurvey\"><TotalPurchaseYTD>0</TotalPurchaseYTD></IndividualSurvey>           | F4C2287D-CE25-4D6A-9D8E-B97D99985DE3 | 2009-01-07 00:00:00 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_24664\\1626439455.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"SELECT * \n",
    "FROM Person.Person\n",
    "WHERE UPPER(FirstName) LIKE UPPER('Michael') AND UPPER(LastName) LIKE UPPER('Allen'); \n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "# Mostrar las primeras filas\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| MiddleName   |    |\n",
      "|:-------------|:---|\n",
      "| E            | E  |\n",
      "| R.           | R. |\n",
      "| B            | B  |\n",
      "|              |    |\n",
      "|              |    |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_24664\\2830211442.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "#Reemplaza los valores nulos en la columna MiddleName de la tabla Person.Person con una cadena vacía.\n",
    "query=f\"\"\"\n",
    "SELECT MiddleName,\n",
    "ISNULL (MiddleName, '')\n",
    "FROM Person.Person\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "# Mostrar las primeras filas\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La anterior solo servia para visualizacion, aca ya hago el update en la tabla\n",
    "update_query = \"\"\"\n",
    "UPDATE Person.Person\n",
    "SET MiddleName = ''\n",
    "WHERE MiddleName IS NULL;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_query)\n",
    "conn.commit()  # Confirmar los cambios en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_24664\\2174076344.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| FechaNacimientoFormateada   |\n",
      "|:----------------------------|\n",
      "| 31/05/2011                  |\n",
      "| 31/05/2011                  |\n",
      "| 31/05/2011                  |\n",
      "| 31/05/2011                  |\n",
      "| 31/05/2011                  |\n"
     ]
    }
   ],
   "source": [
    "#Convierte la columna OrderDate de la tabla Sales.SalesOrderHeader al tipo de dato fecha.\n",
    "query=\"\"\"\n",
    "SELECT FORMAT(OrderDate, 'dd/MM/yyyy') AS FechaNacimientoFormateada\n",
    "FROM Sales.SalesOrderHeader;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "# Mostrar las primeras filas\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_30100\\193837928.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| OrderDate   | DueDate    | ShipDate   |\n",
      "|:------------|:-----------|:-----------|\n",
      "| 2011-05-31  | 2011-06-12 | 2011-06-07 |\n",
      "| 2011-05-31  | 2011-06-12 | 2011-06-07 |\n",
      "| 2011-05-31  | 2011-06-12 | 2011-06-07 |\n",
      "| 2011-05-31  | 2011-06-12 | 2011-06-07 |\n",
      "| 2011-05-31  | 2011-06-12 | 2011-06-07 |\n"
     ]
    }
   ],
   "source": [
    "# Consulta para recuperar datos, incluyendo la columna OrderDate y otras columnas necesarias\n",
    "query = \"\"\"\n",
    "SELECT OrderDate, DueDate, ShipDate  -- Incluye otras columnas necesarias\n",
    "FROM Sales.SalesOrderHeader;\n",
    "\"\"\"\n",
    "# Leer datos en un DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Convertir las columnas de fecha a tipo DATE\n",
    "df = df.assign(OrderDate = lambda x: pd.to_datetime(x['OrderDate']).dt.date)\n",
    "df = df.assign(DueDate = lambda x: pd.to_datetime(x['DueDate']).dt.date)\n",
    "df = df.assign(ShipDate = lambda x: pd.to_datetime(x['ShipDate']).dt.date)\n",
    "# X Es el argumento que la función lambda recibirá. En este caso, x representará cada fila del DataFrame df\n",
    "# x['OrderDate']: Accede al valor de la columna OrderDate en la fila actual (x).\n",
    "# pd.to_datetime(): Esta función de Pandas intenta convertir el valor de OrderDate a un objeto datetime de Pandas. \n",
    "# Cambia la fecha formato\n",
    "# Consulta para crear el esquema Silver\n",
    "# Consulta para crear el esquema Silver\n",
    "# Mostrar las primeras filas del DataFrame modificado\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta para crear el esquema Silver (si no existe)\n",
    "create_schema_query = \"\"\"\n",
    "IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'Silver')\n",
    "BEGIN\n",
    "    EXEC('CREATE SCHEMA Silver')\n",
    "END\n",
    "\"\"\"\n",
    "\n",
    "# Creamos el esquema Silver\n",
    "cursor.execute(create_schema_query)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_30100\\1055318402.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| SalesOrderID   | OrderDate   | DueDate    | ShipDate   | SalesOrderNumber   | AccountNumber   | CustomerID   | SalesPersonID   | TerritoryID   | BillToAddressID   | ShipToAddressID   | ShipMethodID   | CreditCardID   | CreditCardApprovalCode   | CurrencyRateID   | SubTotal   | TaxAmt   | Freight   | TotalDue   |\n",
      "|:---------------|:------------|:-----------|:-----------|:-------------------|:----------------|:-------------|:----------------|:--------------|:------------------|:------------------|:---------------|:---------------|:-------------------------|:-----------------|:-----------|:---------|:----------|:-----------|\n",
      "| 43659          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43659            | 10-4020-000676  | 29825        | 279             | 5             | 985               | 985               | 5              | 16281          | 105041Vi84182            |                  | 20565.6    | 1971.51  | 616.098   | 23153.2    |\n",
      "| 43660          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43660            | 10-4020-000117  | 29672        | 279             | 5             | 921               | 921               | 5              | 5618           | 115213Vi29411            |                  | 1294.25    | 124.248  | 38.8276   | 1457.33    |\n",
      "| 43661          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43661            | 10-4020-000442  | 29734        | 282             | 6             | 517               | 517               | 5              | 1346           | 85274Vi6854              | 4                | 32726.5    | 3153.77  | 985.553   | 36865.8    |\n",
      "| 43662          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43662            | 10-4020-000227  | 29994        | 282             | 6             | 482               | 482               | 5              | 10456          | 125295Vi53935            | 4                | 28832.5    | 2775.16  | 867.239   | 32474.9    |\n",
      "| 43663          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43663            | 10-4020-000510  | 29565        | 276             | 4             | 1073              | 1073              | 5              | 4322           | 45303Vi22691             |                  | 419.459    | 40.2681  | 12.5838   | 472.311    |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m     69\u001b[0m insert_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO [Sales].[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnueva_tabla_silver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(column_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) VALUES (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(column_names))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatos insertados en la nueva tabla \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnueva_tabla_silver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Consulta para recuperar datos, incluyendo todas las columnas necesarias\n",
    "query = \"\"\"\n",
    "SELECT SalesOrderID, OrderDate, DueDate, ShipDate, SalesOrderNumber, AccountNumber, CustomerID, SalesPersonID, TerritoryID, BillToAddressID, ShipToAddressID, ShipMethodID, CreditCardID, CreditCardApprovalCode, CurrencyRateID,   \n",
    " SubTotal, TaxAmt, Freight,TotalDue\n",
    "FROM Sales.SalesOrderHeader;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Leer datos en un DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Convertir las columnas de fecha a tipo DATE\n",
    "df = df.assign(OrderDate=lambda x: pd.to_datetime(x['OrderDate']).dt.date)\n",
    "df = df.assign(DueDate=lambda x: pd.to_datetime(x['DueDate']).dt.date)\n",
    "df = df.assign(ShipDate=lambda x: pd.to_datetime(x['ShipDate']).dt.date)\n",
    "# X Es el argumento que la función lambda recibirá. En este caso, x representará cada fila del DataFrame df\n",
    "# x['OrderDate']: Accede al valor de la columna OrderDate en la fila actual (x).\n",
    "# pd.to_datetime(): Esta función de Pandas intenta convertir el valor de OrderDate a un objeto datetime de Pandas. \n",
    "# Cambia la fecha formato\n",
    "# Consulta para crear el esquema Silver\n",
    "# Consulta para crear el esquema Silver\n",
    "# Mostrar las primeras filas del DataFrame modificado\n",
    "# Reemplazar NaN con None (para que pyodbc los interprete como NULL en SQL Server)\n",
    "df = df.replace({np.nan: None})\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame modificado (opcional)\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "# Nombre de la nueva tabla en la capa Silver\n",
    "nueva_tabla_silver = 'Silver_SalesOrderHeader' \n",
    "\n",
    "# Obtener los nombres de las columnas del DataFrame\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Construir la consulta CREATE TABLE (usando las definiciones de columna proporcionadas)\n",
    "create_table_query = f\"\"\"\n",
    "IF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[Sales].[{nueva_tabla_silver}]') AND type in (N'U'))\n",
    "BEGIN\n",
    "CREATE TABLE [Sales].[{nueva_tabla_silver}] ()\n",
    "    SalesOrderID INT,\n",
    "    OrderDate DATE,\n",
    "    DueDate DATE,\n",
    "    ShipDate DATE,\n",
    "    SalesOrderNumber NVARCHAR(25),\n",
    "    AccountNumber NVARCHAR(15),\n",
    "    CustomerID INT,\n",
    "    SalesPersonID INT,\n",
    "    TerritoryID INT,\n",
    "    BillToAddressID INT,\n",
    "    ShipToAddressID INT,\n",
    "    ShipMethodID INT,\n",
    "    CreditCardID INT,\n",
    "    CreditCardApprovalCode NVARCHAR(15),\n",
    "    CurrencyRateID INT,\n",
    "    SubTotal FLOAT,\n",
    "    TaxAmt FLOAT,\n",
    "    Freight FLOAT,\n",
    "    TotalDue FLOAT\n",
    ");\n",
    "END\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta CREATE TABLE\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insertar los datos en la nueva tabla utilizando executemany (más eficiente)\n",
    "values = [tuple(x) for x in df.values]\n",
    "insert_query = f\"INSERT INTO [Sales].[{nueva_tabla_silver}] ({', '.join(column_names)}) VALUES ({', '.join(['?'] * len(column_names))})\"\n",
    "cursor.executemany(insert_query, values)\n",
    "conn.commit()\n",
    "\n",
    "print(f\"Datos insertados en la nueva tabla {nueva_tabla_silver}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'TotalOrden' agregada y actualizada en la tabla 'Silver_SalesOrderHeader'.\n"
     ]
    }
   ],
   "source": [
    " #Consulta para eliminar la columna existente si existe\n",
    "drop_column_query = f\"\"\"\n",
    "IF EXISTS(SELECT * FROM INFORMATION_SCHEMA.COLUMNS \n",
    "          WHERE TABLE_NAME = '{nueva_tabla_silver}' AND COLUMN_NAME = 'TotalOrden')\n",
    "BEGIN\n",
    "    ALTER TABLE [Sales].[{nueva_tabla_silver}] \n",
    "    DROP COLUMN TotalOrden;\n",
    "END\n",
    "\"\"\"\n",
    "cursor.execute(drop_column_query)\n",
    "conn.commit()\n",
    "\n",
    "# Nombre de la nueva tabla en la capa Silver\n",
    "nueva_tabla_silver = 'Silver_SalesOrderHeader' \n",
    "\n",
    "\n",
    "# Consulta para agregar la nueva columna a la tabla\n",
    "add_column_query = f\"\"\"\n",
    "ALTER TABLE [Sales].[{nueva_tabla_silver}]\n",
    "ADD TotalOrden FLOAT; \n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta para agregar la columna\n",
    "cursor.execute(add_column_query)\n",
    "conn.commit()\n",
    "\n",
    "# Consulta para calcular el total de ventas por SalesOrderID\n",
    "consulta_total_ventas = \"\"\"\n",
    "SELECT SalesOrderID, SUM(OrderQty * UnitPrice) AS TotalVentas\n",
    "FROM Sales.SalesOrderDetail\n",
    "GROUP BY SalesOrderID\n",
    "\"\"\"\n",
    "\n",
    "# Consulta UPDATE para actualizar la nueva columna con los resultados de la subconsulta\n",
    "update_query = f\"\"\"\n",
    "UPDATE T\n",
    "SET T.TotalOrden = S.TotalVentas\n",
    "FROM [Sales].[{nueva_tabla_silver}] T\n",
    "INNER JOIN ({consulta_total_ventas}) S \n",
    "ON T.SalesOrderID = S.SalesOrderID;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(update_query)\n",
    "    conn.commit()\n",
    "    print(f\"Columna 'TotalOrden' agregada y actualizada en la tabla '{nueva_tabla_silver}'.\")\n",
    "except pyodbc.Error as err:\n",
    "    print(\"Error al actualizar la tabla:\", err)\n",
    "    conn.rollback() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_30100\\2039030790.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query_CTE, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| SalesOrderID   | OrderDate   | DueDate    | ShipDate   | SalesOrderNumber   | AccountNumber   | CustomerID   | SalesPersonID   | TerritoryID   | BillToAddressID   | ShipToAddressID   | ShipMethodID   | CreditCardID   | CreditCardApprovalCode   | CurrencyRateID   | SubTotal   | TaxAmt   | Freight   | TotalDue   | TotalSumOrder   |\n",
      "|:---------------|:------------|:-----------|:-----------|:-------------------|:----------------|:-------------|:----------------|:--------------|:------------------|:------------------|:---------------|:---------------|:-------------------------|:-----------------|:-----------|:---------|:----------|:-----------|:----------------|\n",
      "| 43659          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43659            | 10-4020-000676  | 29825        | 279             | 5             | 985               | 985               | 5              | 16281          | 105041Vi84182            | nan              | 20565.6    | 1971.51  | 616.098   | 23153.2    | 20565.6         |\n",
      "| 43660          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43660            | 10-4020-000117  | 29672        | 279             | 5             | 921               | 921               | 5              | 5618           | 115213Vi29411            | nan              | 1294.25    | 124.248  | 38.8276   | 1457.33    | 1294.25         |\n",
      "| 43661          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43661            | 10-4020-000442  | 29734        | 282             | 6             | 517               | 517               | 5              | 1346           | 85274Vi6854              | 4                | 32726.5    | 3153.77  | 985.553   | 36865.8    | 32726.5         |\n",
      "| 43662          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43662            | 10-4020-000227  | 29994        | 282             | 6             | 482               | 482               | 5              | 10456          | 125295Vi53935            | 4                | 28832.5    | 2775.16  | 867.239   | 32474.9    | 28832.5         |\n",
      "| 43663          | 2011-05-31  | 2011-06-12 | 2011-06-07 | SO43663            | 10-4020-000510  | 29565        | 276             | 4             | 1073              | 1073              | 5              | 4322           | 45303Vi22691             | nan              | 419.459    | 40.2681  | 12.5838   | 472.311    | 419.459         |\n"
     ]
    }
   ],
   "source": [
    "#Crea una nueva columna en la tabla Sales.SilverSalesOrderHeader que calcule el total de la orden multiplicando OrderQty y UnitPrice para cada fila.\n",
    "\n",
    "query_CTE = f\"\"\" \n",
    "WITH TotalOrder AS(\n",
    "SELECT ssod.SalesOrderID, SUM(sod.OrderQty*sod.UnitPrice) AS TotalSumOrder\n",
    "FROM Sales.Silver_SalesOrderHeader ssod\n",
    "LEFT JOIN Sales.SalesOrderDetail sod ON ssod.SalesOrderID = sod.SalesOrderID\n",
    "GROUP BY ssod.SalesOrderID \n",
    ")\n",
    "\n",
    "SELECT ssod.*, tor.TotalSumOrder\n",
    "FROM Sales.Silver_SalesOrderHeader ssod\n",
    "LEFT JOIN TotalOrder tor ON ssod.SalesOrderID = tor.SalesOrderID\n",
    "\"\"\"\n",
    "\n",
    "# Leer datos en un DataFrame\n",
    "df = pd.read_sql(query_CTE, conn)\n",
    "# Mostrar las primeras filas del DataFrame modificado (opcional)\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| OrderDate           | OrderYear   |\n",
      "|:--------------------|:------------|\n",
      "| 2011-05-31 00:00:00 | 2011        |\n",
      "| 2011-05-31 00:00:00 | 2011        |\n",
      "| 2011-05-31 00:00:00 | 2011        |\n",
      "| 2011-05-31 00:00:00 | 2011        |\n",
      "| 2011-05-31 00:00:00 | 2011        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_22796\\2972728285.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "#Utiliza una función lambda para extraer el año de la columna OrderDate y crear una nueva columna llamada OrderYear.\n",
    "# Consulta para recuperar datos\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT OrderDate  -- Incluye otras columnas necesarias\n",
    "FROM Sales.Silver_SalesOrderHeader;\n",
    "\"\"\"\n",
    "# Leer datos en un DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "# Convertir explícitamente la columna OrderDate a datetime\n",
    "df['OrderDate'] = pd.to_datetime(df['OrderDate'])\n",
    "# Extraer el año de OrderDate y crear la columna OrderYear\n",
    "df = df.assign(OrderYear=lambda x: x['OrderDate'].dt.year)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame modificado (opcional)\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| OrdenVenta   |\n",
      "|:-------------|\n",
      "| 63363        |\n",
      "| 63364        |\n",
      "| 63365        |\n",
      "| 63366        |\n",
      "| 63367        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_22796\\3196187427.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "#Filtra las órdenes de venta que se realizaron en el año 2014.\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT SalesOrderID AS OrdenVenta\n",
    "FROM Sales.Silver_SalesOrderHeader\n",
    "WHERE OrderDate LIKE '2014%'\n",
    "\"\"\"\n",
    "# Leer datos en un DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame modificado (opcional)\n",
    "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_5312\\230464771.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sales_order_header = pd.read_sql(query, conn)\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_5312\\230464771.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sales_order_detail = pd.read_sql(query1,conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| SalesOrderID   | RevisionNumber   | OrderDate           | DueDate             | ShipDate            | Status   | OnlineOrderFlag   | SalesOrderNumber   | PurchaseOrderNumber   | AccountNumber   | CustomerID   | SalesPersonID   | TerritoryID   | BillToAddressID   | ShipToAddressID   | ShipMethodID   | CreditCardID   | CreditCardApprovalCode   | CurrencyRateID   | SubTotal   | TaxAmt   | Freight   | TotalDue   | Comment   | rowguid_x                            | ModifiedDate_x      | SalesOrderDetailID   | CarrierTrackingNumber   | OrderQty   | ProductID   | SpecialOfferID   | UnitPrice   | UnitPriceDiscount   | LineTotal   | rowguid_y                            | ModifiedDate_y      |\n",
      "|:---------------|:-----------------|:--------------------|:--------------------|:--------------------|:---------|:------------------|:-------------------|:----------------------|:----------------|:-------------|:----------------|:--------------|:------------------|:------------------|:---------------|:---------------|:-------------------------|:-----------------|:-----------|:---------|:----------|:-----------|:----------|:-------------------------------------|:--------------------|:---------------------|:------------------------|:-----------|:------------|:-----------------|:------------|:--------------------|:------------|:-------------------------------------|:--------------------|\n",
      "| 43659          | 9                | 2011-05-31 00:00:00 | 2011-06-12 00:00:00 | 2011-06-07 00:00:00 | 5        | False             | SO43659            | PO522145787           | 10-4020-000676  | 29825        | 279             | 5             | 985               | 985               | 5              | 16281          | 105041Vi84182            | nan              | 20565.6    | 1971.51  | 616.098   | 23153.2    |           | 79B65321-39CA-4115-9CBA-8FE0903E12E6 | 2011-06-07 00:00:00 | 1                    | 4911-403C-98            | 1          | 776         | 1                | 2024.99     | 0                   | 2024.99     | B207C96D-D9E6-402B-8470-2CC176C42283 | 2011-05-31 00:00:00 |\n",
      "| 43659          | 9                | 2011-05-31 00:00:00 | 2011-06-12 00:00:00 | 2011-06-07 00:00:00 | 5        | False             | SO43659            | PO522145787           | 10-4020-000676  | 29825        | 279             | 5             | 985               | 985               | 5              | 16281          | 105041Vi84182            | nan              | 20565.6    | 1971.51  | 616.098   | 23153.2    |           | 79B65321-39CA-4115-9CBA-8FE0903E12E6 | 2011-06-07 00:00:00 | 2                    | 4911-403C-98            | 3          | 777         | 1                | 2024.99     | 0                   | 6074.98     | 7ABB600D-1E77-41BE-9FE5-B9142CFC08FA | 2011-05-31 00:00:00 |\n",
      "| 43659          | 9                | 2011-05-31 00:00:00 | 2011-06-12 00:00:00 | 2011-06-07 00:00:00 | 5        | False             | SO43659            | PO522145787           | 10-4020-000676  | 29825        | 279             | 5             | 985               | 985               | 5              | 16281          | 105041Vi84182            | nan              | 20565.6    | 1971.51  | 616.098   | 23153.2    |           | 79B65321-39CA-4115-9CBA-8FE0903E12E6 | 2011-06-07 00:00:00 | 3                    | 4911-403C-98            | 1          | 778         | 1                | 2024.99     | 0                   | 2024.99     | 475CF8C6-49F6-486E-B0AD-AFC6A50CDD2F | 2011-05-31 00:00:00 |\n",
      "| 43659          | 9                | 2011-05-31 00:00:00 | 2011-06-12 00:00:00 | 2011-06-07 00:00:00 | 5        | False             | SO43659            | PO522145787           | 10-4020-000676  | 29825        | 279             | 5             | 985               | 985               | 5              | 16281          | 105041Vi84182            | nan              | 20565.6    | 1971.51  | 616.098   | 23153.2    |           | 79B65321-39CA-4115-9CBA-8FE0903E12E6 | 2011-06-07 00:00:00 | 4                    | 4911-403C-98            | 1          | 771         | 1                | 2039.99     | 0                   | 2039.99     | 04C4DE91-5815-45D6-8670-F462719FBCE3 | 2011-05-31 00:00:00 |\n",
      "| 43659          | 9                | 2011-05-31 00:00:00 | 2011-06-12 00:00:00 | 2011-06-07 00:00:00 | 5        | False             | SO43659            | PO522145787           | 10-4020-000676  | 29825        | 279             | 5             | 985               | 985               | 5              | 16281          | 105041Vi84182            | nan              | 20565.6    | 1971.51  | 616.098   | 23153.2    |           | 79B65321-39CA-4115-9CBA-8FE0903E12E6 | 2011-06-07 00:00:00 | 5                    | 4911-403C-98            | 1          | 772         | 1                | 2039.99     | 0                   | 2039.99     | 5A74C7D2-E641-438E-A7AC-37BF23280301 | 2011-05-31 00:00:00 |\n"
     ]
    }
   ],
   "source": [
    "#Une las tablas Sales.SalesOrderHeader y Sales.SalesOrderDetail utilizando la columna SalesOrderID.\n",
    "query = \"\"\"\n",
    "SELECT *  \n",
    "FROM Sales.SalesOrderHeader;\n",
    "\"\"\"\n",
    "query1 = \"\"\"\n",
    "SELECT *  \n",
    "FROM Sales.SalesOrderDetail;\n",
    "\"\"\"\n",
    "\n",
    "# Leer los datos en un DataFrame de Pandas\n",
    "df_sales_order_header = pd.read_sql(query, conn) \n",
    "df_sales_order_detail = pd.read_sql(query1,conn)\n",
    "# Unión con FULL JOIN\n",
    "df_merged_full = pd.merge(df_sales_order_header, df_sales_order_detail, on='SalesOrderID', how='outer')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame modificado (opcional)\n",
    "print(df_merged_full.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| BusinessEntityID   | FirstName   | LastName    | JobTitle                     | HireDate   |\n",
      "|:-------------------|:------------|:------------|:-----------------------------|:-----------|\n",
      "| 285                | Syed        | Abbas       | Pacific Sales Manager        | 2013-03-14 |\n",
      "| 293                | Catherine   | Abel        | nan                          | nan        |\n",
      "| 38                 | Kim         | Abercrombie | Production Technician - WC60 | 2010-01-16 |\n",
      "| 295                | Kim         | Abercrombie | nan                          | nan        |\n",
      "| 2170               | Kim         | Abercrombie | nan                          | nan        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_5312\\1989406769.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_Person = pd.read_sql(query2, conn)\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_5312\\1989406769.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_Employee = pd.read_sql(query3,conn)\n"
     ]
    }
   ],
   "source": [
    "#Realiza un LEFT JOIN entre las tablas Person.Person y HumanResources.Employee para obtener información adicional de los empleados.\n",
    "# Consultas SQL para obtener los datos (seleccionando columnas específicas)\n",
    "query2 = \"\"\"\n",
    "SELECT BusinessEntityID, FirstName, LastName \n",
    "FROM Person.Person;\n",
    "\"\"\"\n",
    "query3 = \"\"\"\n",
    "SELECT BusinessEntityID, JobTitle, HireDate\n",
    "FROM HumanResources.Employee;\n",
    "\"\"\"\n",
    "\n",
    "# Leer los datos en un DataFrame de Pandas\n",
    "df_Person = pd.read_sql(query2, conn) \n",
    "df_Employee = pd.read_sql(query3,conn)\n",
    "# Unión con LEFT JOIN\n",
    "df_merged_left = pd.merge(df_Person, df_Employee, on='BusinessEntityID', how='left')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame modificado (opcional)\n",
    "print(df_merged_left.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_5312\\3775163763.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sales_order_header = pd.read_sql(query_sales_order_header, conn)\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_5312\\3775163763.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sales_order_detail = pd.read_sql(query_sales_order_detail, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| BusinessEntityID   | FirstName   | LastName   | TotalVentas   |\n",
      "|:-------------------|:------------|:-----------|:--------------|\n",
      "| 274                | Stephen     | Jiang      | 1111762.00    |\n",
      "| 275                | Michael     | Blythe     | 9324137.16    |\n",
      "| 276                | Linda       | Mitchell   | 10444625.80   |\n",
      "| 277                | Jillian     | Carson     | 10095040.78   |\n",
      "| 278                | Garrett     | Vargas     | 3631749.85    |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_5312\\3775163763.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_employee = pd.read_sql(query_employee, conn)\n"
     ]
    }
   ],
   "source": [
    "#Calcula el total de ventas por empleado uniendo las tablas Sales.SalesOrderHeader, Sales.SalesOrderDetail y HumanResources.Employee.\n",
    "# Consultas SQL para obtener los datos de las tres tablas\n",
    "query_sales_order_header = \"\"\"\n",
    "SELECT SalesOrderID, SalesPersonID\n",
    "FROM Sales.SalesOrderHeader;\n",
    "\"\"\"\n",
    "\n",
    "query_sales_order_detail = \"\"\"\n",
    "SELECT SalesOrderID, OrderQty, UnitPrice\n",
    "FROM Sales.SalesOrderDetail;\n",
    "\"\"\"\n",
    "\n",
    "query_employee = \"\"\"\n",
    "SELECT e.BusinessEntityID, FirstName, LastName\n",
    "FROM HumanResources.Employee e\n",
    "INNER JOIN Person.Person p ON e.BusinessEntityID = p.BusinessEntityID;\n",
    "\"\"\"\n",
    "\n",
    "# Leer los datos en DataFrames de Pandas\n",
    "df_sales_order_header = pd.read_sql(query_sales_order_header, conn)\n",
    "df_sales_order_detail = pd.read_sql(query_sales_order_detail, conn)\n",
    "df_employee = pd.read_sql(query_employee, conn)\n",
    "\n",
    "# Unir las tablas SalesOrderHeader y SalesOrderDetail\n",
    "df_joined = pd.merge(df_sales_order_header, df_sales_order_detail, on='SalesOrderID', how='inner')\n",
    "\n",
    "# Unir el resultado anterior con la tabla Employee\n",
    "df_final = pd.merge(df_joined, df_employee, left_on='SalesPersonID', right_on='BusinessEntityID', how='inner')\n",
    "\n",
    "# Calcular el total de ventas por empleado\n",
    "df_total_ventas = df_final.groupby(['BusinessEntityID', 'FirstName', 'LastName']).agg(\n",
    "    TotalVentas=('OrderQty', lambda x: (x * df_final['UnitPrice']).sum())\n",
    ").reset_index()\n",
    "\n",
    "# Mostrar el resultado sin notación científica\n",
    "print(df_total_ventas.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\", floatfmt='.2f'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
